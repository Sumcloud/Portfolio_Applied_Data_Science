# Portfolio Minor Applied Data Sciences  
**Firstname** : JuliÃ«n  
**Lastname** : van der Niet  
**Student number**: 18069681  
**Date**: 27 December 2021  
**Project group** : IMPutation  

---
# Table of contents  

- [Portfolio Minor Applied Data Sciences](#portfolio-minor-applied-data-sciences)
- [Table of contents](#table-of-contents)
- [Mandatory requirements](#mandatory-requirements)
  - [Datacamp certificates](#datacamp-certificates)
  - [Reflection on group project contributions](#reflection-on-group-project-contributions)
    - [Tasks I worked on:](#tasks-i-worked-on)
    - [Personal STARR-based reflection on writing the paper   <br></br>](#personal-starr-based-reflection-on-writing-the-paper---br)
  - [Reflection on own learning objectives](#reflection-on-own-learning-objectives)
    - [STARR-based reflection on learning objectives](#starr-based-reflection-on-learning-objectives)
  - [Evaluation of the group project](#evaluation-of-the-group-project)
    - [STARR-based reflection on taking more of a leadership role in the last weeks<br></br>](#starr-based-reflection-on-taking-more-of-a-leadership-role-in-the-last-weeksbr)
- [**Subject #1:** Research project](#subject-1-research-project)
  - [Conclusion of our research](#conclusion-of-our-research)
  - [Further research](#further-research)
  - [Visualizations](#visualizations)
  - [Planning](#planning)
  - [Miscellaneous](#miscellaneous)
- [**Subject #2:** Domain knowledge](#subject-2-domain-knowledge)
  - [Literature research](#literature-research)
    - [Miscellaneous literature](#miscellaneous-literature)
  - [Terminology](#terminology)
- [**Subject #3:** Communication](#subject-3-communication)
  - [Presentations](#presentations)
  - [Writing the paper](#writing-the-paper)
    - [Research Proposal:](#research-proposal)
    - [Research paper](#research-paper)
- [Feedback](#feedback)
  - [Feedback from others](#feedback-from-others)
  - [Feedback for others](#feedback-for-others)

# Mandatory requirements  

This chapter will cover the obligatory criteria as stated in the evaluation rubric. The evidence to back up claims made in this portfolio will come in the form of hyperlinks or images of evidence material

## Datacamp certificates  
1. [**Introduction to Python**](https://www.datacamp.com/statement-of-accomplishment/course/0d41e08e0f2b3cc9237a598a8ac822b7c8b05860) 
2. [**Intermediate Python**](https://www.datacamp.com/statement-of-accomplishment/course/4d486123dc053ca2694097de7e6127f81316a876)
3. [**Python Data Science Toolbox (Part 1)**](https://www.datacamp.com/statement-of-accomplishment/course/0651e2ac7e9182f90b8a11e40643bea15787c5c1)
4. [**Python Data Science Toolbox (Part 2)**](https://www.datacamp.com/statement-of-accomplishment/course/4282ff9502056eae87859c5cdfe1e966240187b1)
5. [**Statistical Thinking in Python (Part 1)**](https://www.datacamp.com/statement-of-accomplishment/course/62a89048462af20d499a352afac77a6baf1b42df)
6. [**Statistical Thinking in Python (Part 2)**](https://www.datacamp.com/statement-of-accomplishment/course/d05439b77c7d468bc9a735e6db71b967b174e7db)
7. [**Supervised Learning with scikit-learn**](https://www.datacamp.com/statement-of-accomplishment/course/ef474d922c1b699daac6676f33c3dac3a044b759)
8. [**Linear Classiers in Python**](https://www.datacamp.com/statement-of-accomplishment/course/ce7ee8ac0416e06da1dc158a3e022de9d89954d5)
9. [**Introduction to Data Visualization with Matplotlib**](https://www.datacamp.com/statement-of-accomplishment/course/180fd9544eaea8b77a08b47cf27c9f6a9851d6d3)
10. [**Model Validation in Python**](https://www.datacamp.com/statement-of-accomplishment/course/d61e1e1df9b4d12b30c000d77b671337231b72ae)
11. [**Cleaning Data in Python**](https://www.datacamp.com/statement-of-accomplishment/course/d33d4326e44e7ebf3cc2030ac866dbd3a4167c34)
12. [**Data Manipulation with pandas**](https://www.datacamp.com/statement-of-accomplishment/course/4b4119271c4d139e096e13c65fa9ed8364185db5)
13. [**Exploratory Data Analysis in Python**](https://www.datacamp.com/statement-of-accomplishment/course/eba7ce278a04f06ff54a12d224ec07da44e57c74)
14. [**Manipulating Time Series Data in Python**](https://www.datacamp.com/statement-of-accomplishment/course/4408c464b2f72c80b251a7dd9283d78904d9365a)
15. [**Time Series Analysis in Python**](https://www.datacamp.com/statement-of-accomplishment/course/b2116ff973d5f0d97520a8415189bca1db44879a)
16. [**Joining Data with pandas**](/Datacamp%20Certificates%20Backup/Progress_Joining_Data_with_pandas.png)
17. [**Machine Learning for Time Series Data in Python**](https://www.datacamp.com/statement-of-accomplishment/course/ba3520345411ba3d46f50eb37b683ee9e595ffd5)  

[*Back up of certificates*](/Datacamp%20Certificates%20Backup/)

[*Back to table of contents*](#table-of-contents)<br></br>

---

## Reflection on group project contributions

I didnt't have a specific role during this project, I think I did a bit of everything. However, most of my time has been spent has been spent on both research and the writing of the research paper. I didn't do much on the pipeline but I did work on adding imputation methods found in previous literature and visualizations to visualize method performance.  

The final research paper was my biggest contribution as 90% of it was written by me alone of course with feedback from both group members and teachers. The research included in the paper is also done by me to put our findings in context. The only pieces I didn't write was Hot Deck explanation and I only gave feedback an added to the RNN part.
  

### Tasks I worked on:  

---  
**Research:** 
Explained in [communication](#subject-3-communication) and [research project](#subject-1-research-project)

- [Research proposal](/Research%20Project/Research%20Proposal/Research_proposal_Applied_Data_Science_project_IMP.pdf)
- [Final Word version research paper in PDF](/Research%20Project/Paper/Final%20Version%20PDF.pdf) (Wrote everything except Hot Deck and RNN explanation)
- [Final LaTeX version research paper in PDF](/Research%20Project/Paper/IMP%20Final%20Research%20Paper%20LaTeX%20version.pdf) (Gave feedback on LaTeX layout)
- [Research done](Research%20Project/Paper/Some_studies_found_during_research.pdf)
- Some of the previous versions of the research paper. (Some where in the form of live documents and were not preserved)
  - [Penultimate version in 1-9-2022](Research%20Project/Paper/Penultimate%20version.pdf)
  - [Version 1-7-2022](/Research%20Project/Paper/Version%201-7.pdf)
  - [Version 1-5-2022](/Research%20Project/Paper/Version%201-5-2022.pdf)
  - [Version 1-3-2022](/Research%20Project/Paper/Version%201-7.pdf)
  - [Version 28-12-2021](/Research%20Project/Paper/Version%2028-12-2021%201400%20JUL.pdf)
  - [Version 13-12-2021](/Research%20Project/Paper/Version-13-12-2021.pdf)
  
**Communication:**  Explained in [communication](#subject-3-communication)

- [First internal presentation](/Presentations/Internal%20Presentation%20week%202.pdf)
- [Internal presentation November 8](Presentations/Internal_November_8.pdf)
- [Internal presentation December 6](Presentations/Internal_Week_6.pdf)
- [Internal presentation December 20](Presentations/Internal_December_20.pdf)
- [Preperation External Presentations](https://www.canva.com/design/DAEvc6PSrRc/QSvuCi_b7rpERo3q_xepXA/view?utm_content=DAEvc6PSrRc&utm_campaign=designshare&utm_medium=link&utm_source=sharebutton)

**Applying research/imputation methods:**  

- [Best correlator picker in Dataframe](/Project%20Notebooks/Best_Correlator_Picker.ipynb)
- [KNN distance weighted regression/algorithm](/Project%20Notebooks/KNN)
  - [Example](/Project%20Notebooks/KNN/KNN_K=5.ipynb)
- [Last Observation Carried Forward (LOCF) or forward filling](Project%20Notebooks/forward_fill.ipynb)
- [Time optimized interpolation](Project%20Notebooks/time_interpolation.ipynb)
- [Linear interpolation](Project%20Notebooks/linear_interpolation.ipynb)
- [Bayesian ridge MICE](Project%20Notebooks/bayesian_ridge_MICE.ipynb)
- [ExtraTreesRegressor MICE](Project%20Notebooks/missForest_regressor_MICE.ipynb)
- [Imputation by mean](Project%20Notebooks/mean_imputation.ipynb)
- [Imputation by median](Project%20Notebooks/median_imputation.ipynb)
- [Imputation by mode](Project%20Notebooks/mode_imputation.ipynb)

**Visualizations:**

- [Difference between original and imputed over gap](Project%20Notebooks/Visuals/Trends_diff.ipynb)
  - [Example 1](Project%20Notebooks/Visuals/Images/Trend_difference_smartMeter_power_Hot_deck_gap_type_5_other_index.png)
  - [Example 2](Project%20Notebooks/Visuals/Images/Trend_difference_smartMeter_power_Hot_deck_gap_type_5.png)
- [Missingno Matrix](/Project%20Notebooks/Visuals/missingno_matrix.ipynb)
  - [Example](/Project%20Notebooks/Visuals/Images/Missingno_matrix_smartMeter_power_gap_type_5.png)
- [Evaluation criteria per gap per method in a grouped bar chart](/Project%20Notebooks/Visuals/criteria_grouped_bar_plotter.py)
  - [RMSE example](/Project%20Notebooks/Visuals/Images/Root%20Mean%20squared%20error_per_gap_co2sensor_co2_6_17_33_41.png)
  - [Variation Error Example](/Project%20Notebooks/Visuals/Images/Absolute%20Variance%20error_per_gap_alklimaHeatPump_flow_temp_6_13_34_58.png)
  - [Percent Bias Example](/Project%20Notebooks/Visuals/Images/Percent%20bias_per_gap_smartMeter_power_6_17_33_56.png)
- [Results loader a script to automate graphs from results](/Project%20Notebooks/Visuals/Results_Auto_Loader.py)
- [Value distribution histogram](/Project%20Notebooks/Visuals/distribution_of_meassurements.ipynb)
  - [Example](/Project%20Notebooks/Visuals/Images/Distribution_in_measurements_power_imputed_by_hot_deck_gap_type_5.png) 
- [Change in Value Distribtuion histogram](/Project%20Notebooks/Visuals/change_in_distribution_histogram.ipynb)
  - [Example](/Project%20Notebooks/Visuals/Images/Change_in_distribution_histogram_hotdeck_gap_size_5.png) <br></br>

### Personal STARR-based reflection on writing the paper   <br></br>

**Situation:**  
In the month of December, it was thought that the Research paper was further along than it was at the time. To finish or get close to finishing the paper a time window of a month and a half was created. In the first week of December, it turned out there was not a lot done yet. Which left three weeks before the Christmas break to get a close to the final version draft done. The research was also still very light to support the paper so that needed some work too
Accompanying research for the paper was also in need of improvement to get a starting point for our paper.

**Task:**  
Write the research paper and improve on it iteratively based on the feedback given by teachers and group members. Whilst writing reinforce the research paper with previous literature on the subject. Whilst writing the paper also look for what visualizations to include for getting the point across better.

**Action:**  
I started writing the paper on the third of December and added the required research from what I had read before and was reading. To get everything correct in terms of technical details for our paper I asked every person for a detailed description of how the technical aspects work. These descriptions were rewritten to be included in the paper. 
To get as much feedback as possible I arranged for extra meetings with teachers and made a live document on google drive for group members to give feedback in real-time. Because of the late start, I worked hard on this until the final weekend of the Christmas break. Every three days a new version was sent for feedback during the vacation.
Whilst researching I also made suggestions as to what figures would help get our point across well and later, I wrote code that gave better insight data for our personal evaluation and for the final paper.

**Result:**  
A formatted research paper was written to communicate the research done during this project. Iteratively written to get as much feedback as possible to make sure there were no misinterpretations. Including 3 or 4 figures that were made by me.

**Reflection:**  
Because of the unexpected late start with writing the paper I had to spend a lot of the Christmas break working on the paper. Due to the writing style and other people being busy or not available during the Christmas vacation I wrote the paper mostly by myself. If I had to do this over again, I would probably have checked on the paper sooner to prevent losing time. With writing the paper I would have liked to be more inclusive by convincing other people to write too. Aside from that, I think I communicated clearly what my progress was and what needed feedback to my group members.


## Reflection on own learning objectives  

---
I wanted to use this minor to get an introduction to data science so that I could get an impression on if it is something that interests me as a career choice. I had no specific learning objectives in mind when starting this semester but during the minor, I developed a couple of learning objectives that I wanted to achieve. These were:

1. Writing and submitting a research paper
2. Competency in Python programming
3. Using visualizations and data to draw and support sound conclusions.

I have written research reports and essays before but never a formatted research paper. During this semester I tried to write a well-written paper that could be accepted at an official conference. I personally enjoy writing and feedback given by teachers and our problem owner has given me a better understanding of writing papers.  

I had used Python before but only as a quick scripting language for formatting documents or quick calculations, but it never got much deeper than this. Through the data camp courses, I got a more in-depth understanding of Python programming in normal Python and for Jupyter Notebook. Using Python to make quick and easy visualizations of data has been something I wanted to do for some time and has been a definite highlight for me in terms of Python competency. 

Aside from writing the paper I also wanted to learn about how to make conclusions based on data and its visualizations for a project like this. Learning this and applying the skill in Python and in writing a paper is going to be an asset for later. <br></br>    

### STARR-based reflection on learning objectives  


**Situation:**  
After the pipeline had finished running the imputations and evaluating the selected methods it created a CSV file filled with performance metrics per imputation performed.  The results need to be properly formatted, visualized and studied to make sound conclusions to our research for the paper. This then needed to be written down in a readable fashion for our paper. For the paper a selection of what visuals to include also needed to be made since there was a limit on how many visuals could be included for the conference the paper was going to be submitted to.

**Task:**  
Get the results from the pipeline create visualizations based on the metrics and raw data also format them to make them readable in text. When that is done analyze and study the results achieved by our selected imputation methods and compare them to get the conclusion for our research paper. 

**Action:**  
When the results were in, I downloaded them from the pipeline (Jupyter Notebook server) and loaded them into a visualization script that I wrote. The script automatically generated visuals for the results on selected criteria in the results.csv file. When the results were visualized, I started analyzing the data visualized and in text form to draw conclusions.  

**Result:**  
A sound conclusion was made on the results gotten from the comparison experiment done during our research. The conclusion in the research paper was properly structured and easy to understand for the reader. Visualizations selected for the conclusions also give a visual insight into the performance of the selected imputation methods that further support our conclusion.

**Reflection:**  
Due to the Christmas break, it was hard to get all the group members into one call to give a consensus for our conclusion. To make it work I tried to be as transparent as possible on how the conclusion was made using visuals and data points. I think I succeeded in giving people clear insight into how and why the conclusions were made. 

Thinking back, I would have liked more meetings with the whole group at once to discuss the results in one go. Instead, I made sure to hear everyoneâs opinion in some way or form in a different call or in text format. I would have liked to make more visualizations for the paper but due to restrictions in formatting that wasnât allowed.   <br></br>


## Evaluation of the group project    

--- 

Our group had people of various nationalities, which meant we had to communicate in English instead of Dutch. This was my first English project although I have written English reports before. All group memberâs English-speaking abilities were great, but it still felt hard at times to communicate specific parts of the project. Sometimes it felt in speaking and hearing that the semantics of what some was trying to say fell off which created some small inconsistencies in collaboration.

I think we all got along during this project and the arguments we did have were solved in a mature manner. 

### STARR-based reflection on taking more of a leadership role in the last weeks<br></br>

**Situation:**  
During the last weeks of the project, we as a project group felt a bit aimless. Some group members werenât sure of what they should do but they also were not asking. We were stuck at the evaluation part of the research which made progressing further harder. Exchange students were also going back to their home countries which made physical meetings with the whole group impossible. The fact that all communication now had to be digital, and the holidays made it harder to keep progress steady. 

**Task:**  
Make sure everyone has a task to do for the research project and what their work entails. Deadlines also need to be made clear for keeping progress as smooth as possible when working individually.

**Action:**  
Because I was writing the paper, I had the best overview of what had to be done still to complete our research. When looking at Jira and asking people what they were working on I got an understanding of who was doing what and was available to complete the tasks to be done.
When working physically together at school I asked people in person at school what they were working on and if they could finish a part still to be completed. I also discussed the things I was missing in the research with the group, so everyone understood who did what. While working online I did mostly the same I messaged everyone individually on what needed to be done and when and in the WhatsApp group I also announced who did what. 
On January 4th we met to finish the paper and for that, the task people were tasked with needed to be done. To make it clearer on what was expected from everyone I created an agenda points document. Jan 4th didnât turn out to be the finishing date but for the other days, I created a similar document or message.

[Example of agenda point document](/Research%20Project/Agenda_points_for_jan_4th.pdf)
<details>
  <summary>Image agenda point document</summary>
  <img src="/Research%20Project/Image_Agenda_Points_Document.png" alt='image agenda point document'>
</details>  

**Result:**  
Clearer coordination and communication within the group everyone knew what they were supposed to do before Jan 4th and other dates. It also helped writing the paper because it made it easier to communicate when a new version of the paper was ready for feedback.

**Reflection:**  
The group should probably have appointed someone as a âleaderâ it felt we were a bit aimless at times. This was also due to some people being very reactive instead of active. Whether it was me or someone else doesnât really matter to me. But I feel that if I started being more assertive earlier on in the project, we could have had a more balanced workload for the pipeline and paper. This would probably have resulted in a more gradual improvement too compared to the explosive bursts we had in progress.   

# **Subject #1:** Research project  

The project I worked on was project-imputation or IMP, the goal of the project was to create a guideline for the imputation of Building Management System (BMS) time-series data. The client for this project was the research group Energy in Transition (EiT), a research group from THUAS. During the project, we had constant contact with our contact person at EiT Mr. Baldiri Salcedo Rahola. EiT provided the research group with the datasets used for the research. The datasets contained data from 120 BMS units placed in terraced houses collected over the year 2019. Aside from BMS data our research also used meteorological data from KNMI. This data set contained climate recordings from 2018-2021 and included measurements taken by 25 weather stations throughout the Netherlands.  

BMS measurements in our data set were supposed to be at an interval of five minutes but due to sensor malfunction or data storage errors, these values can be lost. These losses add up and cause inconsistencies down the line in downstream applications of the data. An example of this can include worsened performance in forecasting in cases with enough data missing. 

To get the view of the project group, the teachers, and the client in line a research proposal was created to create an outline for our research. To form our research question and corresponding sub-questions preliminary literature research was done to see what previous work could be built upon.  
The proposal contained our research questions as listed below:

**Main-question:**  
 - Which imputation techniques should be applied for data imputation in building energy time series data?  

**Sub-questions:**  
  1. What imputation methods are known for imputing time-series data?
  2. Which imputation methods are best suited for what gap sizes
  3. What imputation methods are best suited for which types of data?  

**Explanation:**

The first sub-question allowed us to orientate ourselves more in previous literature to find what methods have precedent in the field. The selection of imputation methods that were included was 4 but more methods outside those four were tested internally.   

Due to the nature of some imputation methods (some imputing dynamic or static values) performance on various amounts of missing data and gap sizes is to be expected. During our preliminary desk research that was confirmed which led us to include this as a research question. To mimic gaps found in real data a gap creation algorithm was made to create artificial gaps randomly according to rules set in a config file. This allowed us to test the performance of each method in a controlled environment.   

From preliminary research done in the first weeks of the project, we found that some methods of imputation will most likely perform better on certain data measurements scales. This led us to include it as a research question for our project. The conclusion of research question 3 formed the scenarios for the guideline together with the second question. Our data sets didnât contain all measurement scales because of the nature of the data set ordinal scale data wasnât included. The nominal data also was numerical and not text-based.
The main research question was answered by testing the methods found in sub-question 1 and testing their performance in sub-question 1 and 2. The conclusion to our paper came in the form of a guideline of what imputation method to use with what data measurement scale and gap size.

During our research, we deviated from the research proposal as imputing trends back into missing data became a focal point. This also meant a change in evaluation metrics as RMSE might not evaluate the ability to impute trends well. For this reason, Variance Error or VE was chosen to evaluate our imputation performance. RMSE was still included in the final paper as it is a common evaluation metric in many previous works.

For our paper we used various abbreviations to make things clearer a table explaining them is found below.

| Abbreviation| Term in full |
|----------------:|-----------:|
|RMSE| Root Mean Squared Error|
|VE| Variance Error|
|HD| Hot Deck|
|RNN|Recurrent Neural Network|
|GRU|Gated Recurrent Units|
|KNN|K-Nearest Neighbour|
|LOCF|Last Observation Carried Forward|



## Conclusion of our research  

**NOTE!: these conclusions might overlap with the paper, the conclusions are my own but since I wrote the conclusion with feedback and confirmations from Adrien and Albert they are naturally overlapping.**

The goal of our research project was to create a BMS imputation guideline for scenarios with different gap sizes and data scales. The conclusion of the paper resulted in the table below. 

There are many imputation methods that have precedent in previous work for imputing time-series data. During our project, not all could be evaluated but some of the methods we have tried are Hot Deck (HD) and KNN. For the final paper, we selected four methods to keep things compact.  

When looking at the results there is no method that is the best for a single gap size across all imputation targets. There is no consistent method that scores best on single gap size. With some exceptions, methods seem to be very much bound to the data scale they performed the best in.

The results are very decisive when it comes to which imputation method is best for what data measurement scale. According to our results, RNN performs the best on interval data compared to other methods and HD is the best performer on both Ratio and Nominal scaled data.

The scenarios as described in the table below are combinations of data measurement scale and gap size. RMSE and VE both give the same result, so the table is representative of the recommendations as evaluated by both metrics.


| Guideline table | Gap type 1 | Gap type 2 | Gap type 3 | Gap type 4 | Gap type 5 | 
|----------|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|
|**Nominal**|HD|HD|HD|HD|HD|
|**Ratio**|HD|HD|HD|HD|HD|
|**Interval**|RNN|RNN|RNN|RNN|RNN|

[**The values this table was based on can be found here**](/Research%20Project/Paper/Results%20Based%20on%20VE%20and%20RMSE.pdf)

**Legend for reading the line graph & bar charts below**  
ð¦ = KNN (With the best K selected for each gap)  
ð§ = LOCF  
ð© = RNN (RNN)   
ð¥ = Hot Deck (HD)

*Line graph only*  
ð¦ = Reference data  
Dashed ð¦ = Hot Deck --



Outside the main conclusion several other smaller conclusions can be made based on the imputation results from our experiment. These smaller conclusions are:

- The RMSE results show that the imputations done in this study are poor when compared to previous literature. <details><summary>All RMSE scores</summary><img src="/Research%20Project/Paper/All%20RMSE.jpg"></details>

- HD tends to do better in the KNMI datasets compared to RNN. This might be due to there being more regularity in data and thus more similar trends. An interesting example of this in the KNMI temperature data where HD beats RNN by a small margin but in flow_temp it loses to RNN with a wide margin in both VE and RMSE. In the image below you can see that even in interval data (which was the best data scale for RNN) HD comes close or beats RNN in KNMI data but drops off in the BMS data. 
  <details>
  <summary>Example of HD performance in KNMI vs BMS</summary>
  <img src="/Research%20Project/Paper/Comparison%20Flow_temp%20and%20Temperature.jpg" alt = 'comparison KNMI and BMS'>
  </details>  
  
- RMSE and VE do not always align when it comes to accurately evaluating the ability to impute a trend back into the missing data. A good example of this is CO2 gapsizes 3 and 4, the RMSE is score is relatively close between RNN and HD while the VE score is far apart.   
When looking at the bar charts it can be seen that according to RMSE the performance of RNN and HD is way closer than the VE would suggest. But in the line graph below it can be seen that HD is trying to impute a trend and RNN is imputing a more stable is imputed. In this case RMSE heavily 'punishes' HD for imputing trends whilst RNN gets 'rewarded' for imputing a more stable value.  Don't get me wrong RMSE does what it is supposed to do here it rewards single prediction more than the overall trend but what can be said is that VE is the better indicator here.   <details>
  <summary>Co2 gap size 4 visual</summary>
  <img src="/Research%20Project/Paper/combine_images.jpg">  

  <img src="/Research%20Project/Paper/CO2%20Sensor%20Gap%204.png" alt="Co2 gap size 4 visual">
</details>
  

- In the acheived results no strong link can be found between having multiple strong correlators and a good RMSE or VE score. Flow_temp had two strong correlators in heat pump power usage and return temperature and got good imputation results. Power and CO2 results however seem to contrast these findings, as power and co2 both had one or two decent to strong correlators but both got worse results. In the image below the VE and RMSE are displayed and it can be seen that RNN performs worse on both power and CO2 compared to its performance in flow_temp and with HD. The amount of good correlators doesn't seem to be the reason of RNN's worse performance in ratio data when compared with interval scale data.<details><summary>CO2 Power and Flow_temp charts</summary><img src="/Research%20Project/Paper/Flow_temp%20Co2%20Power.jpg"></details>

- In previous research, it was found the distribution to matter when training and imputing data across different units. To measure, the impact of this factor the Kurtosis and Skewness of both the training and imputation target were recorded. From our results, we can conclude that there was no consistent impact of a difference in Kurtosis or Skewness affecting our results. The CO2 sensor data had a high difference in both Kurtosis and Skewness and that might have affected the RNN somewhat. However, when looking at other features like flow_temp or power that same effect doesnât show the same result. The difference in Kurtosis or Skewness canât explain the worse performance of RNN on ratio data.

## Further research

Future research should focus on using the imputed data for forecast/predicting future power usage or other sensor data and seeing the impact each method has on its results. This would give researchers a real-world insight into the effect of imputation instead of it just being evaluated based on things such as error metrics.  

The data sets that were used in our study contained only numerical data and no ordinal data. To get a full view of the imputation performance on text-based categorical data further research is required.

Our paper also talked about an imputation methodâs ability to follow trends however, some of the methods included in the paper by nature couldnât do this (e.g. LOCF). Future research should keep trend imputation into account and should then select methods for that goal accordingly. 

The GRU RNN architecture used in our research had clear limitations based on how it was set up. To evaluate the full potential of BMS time-series imputation using RNN the architecture should be changed to an encoder-decoder sequential based design. This would remove the potential bias of imputation using its own imputed values.

To see if Hot Deck is truly a viable method for the imputation of BMS data more research will have to be done when the data sets aren't as similar. Since the buildings in this study are all in the same neighbourhood trends in power usage are very similar. This might not apply to future research as well as it did in our paper and should therefore be evaluated further.

## Visualizations

To help make conclusions about the data I made visualizations of the results per imputation target and evaluation criteria. These visuals were automatically generated when loading data in a script I wrote. 

- [Link to the script here!](Project%20Notebooks/Visuals/criteria_grouped_bar_plotter.py)  
- <details><summary>Example image</summary><img src="/Project%20Notebooks/Visuals/Images/Average%20variance%20error_per_gap_Temperature_9_20_2_37.png" alt="Variance average temperature" ></details>
- [Other examples](/Research%20Project/Paper/Graph%20examples.pdf)

To get ideas for visualizations to include in the paper I experimented with some visuals. Sadly because of the CLIMA-format heavily restricting the use of visuals many of these concepts didn't make it into the paper. Again these visuals were exploratory and for internal use only.   
The visual concepts included:

- Missingno matrix <details><summary>Example</summary><img src="/Project%20Notebooks/Visuals/Images/Missingno_matrix_smartMeter_power_gap_type_5.png" alt="missingnomatrix"></details>
- Change in distribution<details><summary>Example</summary><img src="Project%20Notebooks/Visuals/Images/Change_in_distribution_histogram_hotdeck_gap_size_5.png" alt="change in distribution"></details>  
- Distribution histogram <details><summary>Distribution histogram</summary><img src="/Project%20Notebooks/Visuals/Images/Distribution_in_measurements_power_imputed_by_hot_deck_gap_type_5.png" alt="distribution"></details>
- Trend indicator line graph <details><summary>Example</summary><img src="/Project%20Notebooks/Visuals/Images/Trend_difference_smartMeter_power_Hot_deck_gap_type_5_other_index.png" alt="trend difference Hot Deck gap type 5"></details>

When it came to writing the paper the concept became explanatory and were made easier to read for a wider audience.

- Trend Indicator line graph<details><summary>Example</summary><img src="/Project%20Notebooks/Visuals/Images/Flow_temp.png" alt="Improved trend indicator"></details>

## Planning
At the start of the project we made a verbal agreement on what to finish when. Our goal was to present the research phases during the external presentations but we deviated from that when it came into practice. During the first weeks we had meetings once or twice a week but later on we upped that to daily meetings.

For visualizing our KANBAN board we made of use of JiRA. Tasks were added weekly on Thursdays after meeting together and with teachers and at the end of each sprint we added backlog tasks for the next one. We didn't do traditional retrospectives but at the end of each sprint (which was always a Thursday) we discussed what we had done and what needed extra attention for the next sprint.

Some weeks of the project had to be spent online due to COVID restrictions and in those weeks we held online daily standups to remain productive. During this project I had to go in to a quarantine  because a close relative got COVID, this lasted 2+ weeks which made it hard to keep as involved in the project.

<details>
  <summary>Jira Sprint example</summary>
  <img src="Research%20Project/JiRa%20sprints/Sprint_6.png" alt="Sprint 6">

  [Sprint backup image](/Research%20Project/JiRa%20sprints/Sprint_6.png)
</details>  

## Miscellaneous 

During the project I have done research to back up our findings. These studies can be found [here](/Research%20Project/Paper/Some%20of%20the%20studies%20found%20and%20described.pdf) formatted in a table. More papers were read but because only the most relevant papers were kept the list can feel relatively short. 

[Back to table of contents](#table-of-contents)


# **Subject #2:** Domain knowledge

This project focused on imputing Building Management System (BMS) time-series data. BMSâs generate data from various sensor measurements at set time intervals. Examples of these sensors are the current operational mode of a heat pump, heat pump water flow temperature, power usage and CO2 measurements. However, sometimes data can get lost by things like sensor or data storage malfunction. Lost data in large enough quantities cause forecasting models to be less accurate and can thus by proxy result in less living comfort for the residents or worse building system shutdown. 

This is where imputation comes in, to bring back the lost data many methods can be used with various backgrounds e.g., Statistical, Linear or Neural Network-based methods. For smaller gaps simpler methods can be used with relative success but in larger sequences of missing data more complex methods ought to be used. Examples of simpler methods are Last Observation Carried Forward and Linear interpolation. LOCF works by placing the last valid observation on the entirety of the gap and Linear interpolation calculates a linear trend between the value before and after a gap.
More complex methods would include Neural Network or machine learning based solutions. 

Data from things like power usage can be hard to impute because the data changes rapidly and is very volatile. When imputing things like power usage or flow temperature it can be useful to know trends since people have certain habits. The imputation of trends is also important for the same reason as it gives better insight into downstream applications of the data. 

Because our buildings are becoming smarter and smarter and more dependent on data to regulate the efficiency of their processes completeness of data is vital. There has been a lot of research into the imputation of BMS data to make the buildings of the future more efficient. Our research aimed to create a guideline on when to use what imputation method for what measurement scale of data and amount of data missing. 

Another focus of our research paper was to evaluate an imputation methodâs ability to impute a trend back into the missing data. Previous literature used an evaluation metric called Root Mean Squared Error (RMSE) which in different circumstances is a good metric to evaluate imputation performance with. Because RMSE cares more about the total accuracy of imputation than a trend being followed it can give misleading insight into an imputation methodâs ability to impute trends.

For our research, a different metric was chosen namely the Variance Error (VE). It is calculated by calculating the difference in the variance of data in original and imputed data. RMSE was still included in the paper as a comparison point for previous and future research. RMSE tended to match VE but in some cases, RMSE scores indicated a different conclusion than VE but the trend imputation was correctly evaluated by VE. 


## Literature research

To gain knowledge on the specific domain of the imputation of BMS time-series data studies were used that are included in the final paper.
Those can be found [here](Research%20Project/Paper/Some_studies_found_during_research.pdf).

To highlight some of the research found:  

- Liang Zhang (2020), A study into the imputation of BMS time series data using a comparative experiment.This gave me a good idea of the current work done in the domain.
https://doi.org/10.3390/s20205947 

- Mel Keytingan (2020), What methods have precedent in the field and what to take into account when dealing with seperate data units.  
  https://doi.org/10.1016/j.dibe.2020.100037
-  Mehdi Pazhoohesh (2019), Not especially similar data set as it uses lighting data instead of things like power. Still gives good precedent on methods to include when imputing time series.
    https://doi.org/10.1109/sege.2019.8859963

### Miscellaneous literature
- Stef van Buuren's book Flexible Imputation of Missing Data, this was useful when starting out with imputations. https://stefvanbuuren.name/fimd/
- Some articles from [towards data science (medium.com)](https://towardsdatascience.com/) for example this [article](https://towardsdatascience.com/a-comprehensive-guide-to-data-imputation-e82eadc22609). They were quite useful to get some layman's knowledge in the field.
- Books such as: Introduction to machine learning with Python & Datascience from scratch first principles with Python.


## Terminology 

|Term   |Explanation|
|:------|:----------|
|Imputation|Replacing the missing values with substituted data|
|Variance| mean squared difference between each observation and the centre of distribution meaning the average|
|Kurtosis|Statistical indicator of the peakedness in distribution of data. Data sets with a high Kurtosis value will be heavily tailed and ones with low Kurtosis values will be light tailed in their distribution.|
|Skewness|Meassure of asymmetry in probability distribution about its mean|
|Variance Error| The difference in variance present in original and imputed data|
|Root Mean Squared Error|Common use imputation evaluation metric calculated by taking the square root of the mean squared error. Advantage is that is in the scale of the data i.e data it is in Watts RMSE is in Watts.|
|Time-series data|A series of observations indexed by a timestamp|
|Data velocity|How quickly data is generated in our case supposedly every 5 minutes|
|Machine learning|Systems that are able to learn without explicit instructions by using algorithms and other statistical values to make conclusion based on patterns observed in data.|
|Neural Network|Algorithms that mimic the process of the human brain to recognize patterns in data sets.|
|Underfitting| Situation where model doesn't perform well on training data (probably real world too.) and makes assumptions about data e.g. data is linear.|
|Overfitting| Situation where model does well on training data but doesn't generalize well in real world data. Overfitted models also tend to be too sensitive.|
|Regression| Algorithmic method that is used to predict numerical values. The algorithm tries to understand to understand the dependency relationship between data to be more accurate.|
|Classification| Predictive model that is used to predict class labels using input data.|
|Building Management System (BMS)| BMS also known as building automation systems are smart building systems that control things like solar panel power generation. BMS systems generate data that can be used to forecast future power usage so that efficiency can be improved in the future.|
|Interval scale| Numerical data with order that has no true zero e.g. temperature in Celcius|
|Ordinal scale|Categorical values that have order in them e.g. survey answers completely disagree - completely agree|
|Ratio scale|Numerical data that has order and a true zero e.g. temperature in Kelvin |
|Nominal scale| Categorical data that doesn't have order e.g. country or gender|

[Back to the table of contents](#table-of-contents)

# **Subject #3:** Communication

To communicate the progress and results of our research I presented four internal presentations and assisted in preperation with two external presentations. In the first weeks of the project I wrote the Research proposal together with Ramon van der Elst. During the last months of the project I wrote the final research paper of our project.

## Presentations

**Internal presentations I created and presented:**  

- [Internal presentation September 6](/Presentations/Internal%20Presentation%20week%202.pdf)
- [Internal presentation November 8](Presentations/Internal_November_8.pdf)
- [Internal presentation December 6](Presentations/Internal_Week_6.pdf)
- [Internal presentation December 20](Presentations/Internal_December_20.pdf)

**External presentations I assisted with in preperation:**

- [External presentation Week 6](/Presentations/Team%20IMP%20-%20external%20presentation%20week6.pdf)
- [External presentation Week 14](/Presentations/Imputation%20Project%20team%20Internal%20presentation%20week14.pdf)

**For each presentation I created the following file structure:**
```
  Presentation folder/
    Images/
      image_1.png
    Presentation file week X.pptx
    Work Description per person.docx
```

The word document was used for everyone to describe their work in the last weeks. The Images folder was used to add visuals for the powerpoint. I found this structure to be the most clear and easy to use when working on this group project.
<details>
  <summary><i>Example 1</i></summary>
  <img src="Presentations/Structure/Example_1.png" alt="Example 1">

  **Back-up:** [*Example_1*](Presentations/Structure/Example_1.png)
</details>

<details>
  <summary><i>Example 2</i></summary>
  <img src="Presentations/Structure/Example_2.png" alt="Example 2">

  **Back-up:** [*Example_2*](Presentations/Structure/Example_2.png)
</details>

## Writing the paper  

---  

As stated in my learning objectives I wanted to create a paper based on our research and submit it to the CLIMA conference. 

### Research Proposal:  
To get on the same line with each other in the group and with the client and teachers a research proposal was created. During the project we deviated from some of the outlines in the proposal but I see that as only natural due to it being very early on in this minor. The research proposal was written collaboratively with Ramon van der Elst. The rest of the research group gave constant input to get a research proposal we all agreed with. 

*Parts that I wrote for the research proposal:* Introduction, Research Questions (With input from group ofcourse), Background & context, Methodology

**Proof of work:**  

- [Research proposal document](/Research%20Project/Research%20Proposal/Research_proposal_Applied_Data_Science_project_IMP.pdf)
- <details><summary>Editing history research proposal 1 </summary><img src="/Research%20Project/Research%20Proposal/Version%20History/Version_History_October%203-14.png"></details>

- <details><summary>Editing history research proposal 2 </summary><img src="/Research%20Project/Research%20Proposal/Version%20History/Version_History_September%2023_October_2.png"></details>

- To see version history of the research proposal go to Google docs [(->link<-)](https://docs.google.com/document/d/1RehSUVk_NFjkZ0QC1pMuIAnE69TpEE6o0C73XAbNcgM/edit?usp=sharing) and go to: 
  file>version history>see version history


### Research paper

For the paper I wrote the following: Abstract, Introduction, Methodology (Except for Hot Deck and Recurrent Neural networks), Results and Discussion and the conclusion. I adjusted to feedback given by teachers especially Baldiri gave a lot of feedback. He shortened my sentences by large amounts and I adapted to his feedback. 

During the Christmas break I sent versions of the paper to individual groupmembers (mostly Ramon van der Elst) for feedback. The research paper was also uploaded to google drive with every iteration to get as much feedback as possible. The last versions were edited in drive only as that reduced confusion as to what was the most recent version. 

Parts I wrote for the research paper (I wrote these pieces by myself 100%):

- Abstract
- Introduction
- Methodology (Except for Hot Deck and RNN (I only rephrased the RNN and added Correlation part))
- Results and discussion
- Conclusion

My local versions of the research paper:

  -  [Last version of the paper](/Research%20Project/Paper/Version-1-12-2022.pdf)
  - [Penultimate version in 1-9-2022](Research%20Project/Paper/Penultimate%20version.pdf)
  - [Version 1-7-2022](/Research%20Project/Paper/Version%201-7.pdf)
  - [Version 1-5-2022](/Research%20Project/Paper/Version%201-5-2022.pdf)
  - [Version 1-3-2022](/Research%20Project/Paper/Version%201-7.pdf)
  - [Version 28-12-2021](/Research%20Project/Paper/Version%2028-12-2021%201400%20JUL.pdf)
  - [Version 13-12-2021](/Research%20Project/Paper/Version-13-12-2021.pdf)

Later on we switched to a Google drive live document:

- [Link for the drive document](https://docs.google.com/document/d/1FVeg5uGtCNqQEdwu1R0kmPcDqkFb2P3E/edit)

For the final LaTeX format I gave feedback to Michael to improve the paper layout. 

- [LaTeX paper](Research%20Project/Paper/IMP%20Final%20Research%20Paper%20LaTeX%20version.pdf)

When writing the conclusion and I made sure to confirm every conclusion with both Albert Corson and Adrien Lucbert. Via Teams I gave an explanation using the exploratory visuals I made to see if they saw the conclusion that I saw. For full transparency and to get as much feedback as possible I sent the generated Barcharts in the whatsapp group so that everyone could give informed feedback and conclusions.

<details>
<summary>Barcharts in whatsapp groups
</summary>
<img src="/Research%20Project/Barcharts-in-whatsapp.png">
</details>  

Ramon van der Elst has been especially helpful in his feedback for the paper. Thanks to him a lot of spelling and grammar errors were removed.

[Back to the table of contents](#table-of-contents)
  
# Feedback
As a group we forgot to make use of the 360 degree feedback tool. To make up for this I decided to ask for feedback on personal performance for this portfolio. **NOTE!:** I did get 
permission to include their feedback in this portfolio.

## Feedback from others

<details>
  <summary>Adrien Lucbert</summary>  

  **+** leader/coordinator behaviour  
  **+** rigorous  
  **-** uneven workload throughout the duration of the minor    

  **Explanation:** JuliÃ«n endured the scrum master role, he made sure everyone in the team communicated on what they were doing or had trouble with. He has been someone we could rely on to get the work done and was willing to tackle literature work, which allowed most of us to focus on the practical work. But I feel like he has been less present at times, and working too much at other times, especially at the end, which could sometimes be hard for him to handle.

</details>

<details>
  <summary>Albert Corson</summary>

  **What went well:**    

  - Willing to work  
  
  **What could be improved:**   

  - Coordination/Communication
</details>

<details>
  <summary>JesÃºs MartÃ­nez De Juan</summary>

  **+** Good desire to work
  **+** Some previous knowledges  
  **+** Productivity even when Julien had to quarantine  
  **-** Spending too much time in methods that didn't worked at the end (but we didn't know previously)  

  **Explanation:** I'm glad to have worked with Julien and all the members of the group. He has always good willing to work and he took the lead in taking notes of all the meetings we had so we can have the main important points clearly.
  
</details>

<details>
  <summary>Michael Weij </summary>  

  **+**  Julien took up to do most of the communication within the team which was really nice. Which made it easy to know what everybody was responsible for.  Because of that it was easy to work together.
  
  **-**  In the second half we decided to work more on site so we could finish the project in time. But most of the time you still decided to work from home. I think it was better for the project if you were more on site overall.  


  **Explanation:** It was nice working with Julien he did everything he was said he was going to do and made sure everybody was on the right track.    

  
</details>

<details>
  <summary>Ramon van der Elst </summary>  
  
  **+** Very communicative and clear throughout the project.  
  **+** Took on a lot of work and with his perfectionistic approach showed some good results.  
  **-** Sometimes takes on the work alone and should try to work together more often. 

  
</details>

## Feedback for others
<details> 
  <summary>Adrien Lucbert</summary>

  **+** Hardworking  
  **+** Active contributions during group only meetings or with teachers  
  **+** Enthusiastic  
  **-** Didn't ask for help  

  **Explanation:** 
  Adrien has been an absolute pleasure to work with during this semester, he was a hard worker and was one of the few people who actively contributed during meetings either internal or with teachers. At times he pulled too much work towards him, this created a bit of an uneven workload. He did his work without asking for other people to assist him in his work, which made it harder for people to assist him when needed. In the end, his enthusiastic attitude and contributions have been vital to the success of our project.

</details>

<details>
  <summary>Albert Corson</summary>

  **+** Active contributions during group only meetings or with teachers  
  **+** Hard worker  
  **-** Communication and coordination was hard at times  
  **Explanation:**
  Overall Albert has been a pleasure to work with, he was a big contributor to the project with the custom Hot Deck method and improvements to the pipeline. He was also one of the few people during meetings who would speak up and ask for clarification during meetings internal or with teachers. Coordinating was a bit hard at times but that is was mostly when working online and those problems subsided when we moved to in person when it was possible.
  
</details>

<details>
  <summary>JesÃºs MartÃ­nez De Juan</summary>

  **+** Adept  
  **-** Was hard to communicate and coordinate with  
  **-** Was passive during meetings  
  
  **Explanation:** To be honest I haven't worked with JesÃºs much because he was largely focused on Neural Networks from the start of the project. During meetings he didn't add much and needed to be asked in order to contribute.  
</details>

<details>
  <summary>Michael Weij </summary>  

  **+** Good communication  
  **+** Good attitude  
  **-** Could have helped with Research    

  **Explanation**
  Michael and I haven't worked on the same taks during the project so I can't speak to the indiviudual quality of work aside from the LaTeX format due to his work being largely collaborative. I found his attitude during the project to be sharp and his punctuality for deadlines to gives me the same feeling.

</details>

<details>
  <summary>Ramon van der Elst </summary>  

  **+** Good at presenting especially the external presentations  
  **+** Good critical feedback on paper  
  **-** Didn't ask for help  
  **-** Passive during meetings group only and with teachers

  **Explanation:** Ramon's part for this project was writing the paper and researching previous studies to make writing the paper and the research process easier. During the last month a lot had to be done on his earliest draft of the paper, due to the fact that he had never asked for feedback from us or the teachers. The research he did also didn't overlap quite well to what was required in terms of technical aspects of the paper. This was largely due to him not asking questions for technical processes that the other group members were working on. This also showed in his paper where some clear misconceptions and lack knowledge of ongoing technical processes were apparent. In the last weeks I rewrote his first version and added some papers that I found during research. His feedback has been important for the improvement of the paper and his presentation skills were also a big help to communicating the goals, processes and results of our research. 
</details>

[Back to table of contents](#table-of-contents)
   
